{"class":"org.apache.spark.ml.feature.Tokenizer","timestamp":1578387152486,"sparkVersion":"3.0.0-preview","uid":"Tokenizer_debae9b94f41","paramMap":{"outputCol":"words","inputCol":"text"},"defaultParamMap":{"outputCol":"Tokenizer_debae9b94f41__output"}}
